'use client';

import { useState, useRef, useEffect } from 'react';
import { Camera, Upload, Mic, X, Loader2 } from 'lucide-react';

interface AudioCaptureResult {
  audioData: string;
  transcript: string;
}

interface MediaInputProps {
  onImageCapture: (imageData: string) => Promise<void>;
  onAudioCapture: (result: AudioCaptureResult) => Promise<void>;
  currentImage?: string;
  currentAudio?: string;
  onClear: () => void;
  onCancelRecognition?: () => void;
  disabled?: boolean;
  isRecognizing?: boolean;
}

export type { AudioCaptureResult };

const createDeferred = () => {
  let resolve: () => void;
  const promise = new Promise<void>((res) => {
    resolve = res;
  });
  return {
    promise,
    resolve: resolve!
  };
};

export default function MediaInput({
  onImageCapture,
  onAudioCapture,
  currentImage,
  currentAudio,
  onClear,
  onCancelRecognition,
  disabled = false,
  isRecognizing = false
}: MediaInputProps) {
  const [isRecording, setIsRecording] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false);
  const [recordingTime, setRecordingTime] = useState(0);
  const [progress, setProgress] = useState(0);
  const [progressMessage, setProgressMessage] = useState('');
  const [interimTranscript, setInterimTranscript] = useState('');
  const [finalTranscriptDisplay, setFinalTranscriptDisplay] = useState('');
  const fileInputRef = useRef<HTMLInputElement>(null);
  const cameraInputRef = useRef<HTMLInputElement>(null);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const recordingTimerRef = useRef<NodeJS.Timeout | null>(null);
  const progressTimerRef = useRef<NodeJS.Timeout | null>(null);
  const completionTimerRef = useRef<NodeJS.Timeout | null>(null);
  const wasProcessingRef = useRef(false);
  const recognitionRef = useRef<any>(null);
  const isRecognitionActiveRef = useRef<boolean>(false);
  const recognitionEndDeferredRef = useRef<ReturnType<typeof createDeferred> | null>(null);
  const finalTranscriptRef = useRef<string>('');
  const interimTranscriptRef = useRef<string>('');
  const mediaStreamRef = useRef<MediaStream | null>(null);

  useEffect(() => {
    const isActive = isProcessing || isRecognizing;

    if (isActive) {
      wasProcessingRef.current = true;
      if (completionTimerRef.current) {
        clearTimeout(completionTimerRef.current);
      }
      if (progressTimerRef.current) {
        clearInterval(progressTimerRef.current);
      }
      setProgress(0);
      progressTimerRef.current = setInterval(() => {
        setProgress(prev => {
          if (prev >= 92) {
            return prev;
          }
          const next = prev + Math.random() * 12 + 6;
          return next >= 92 ? 92 : next;
        });
      }, 450);
    } else {
      if (progressTimerRef.current) {
        clearInterval(progressTimerRef.current);
        progressTimerRef.current = null;
      }

      if (wasProcessingRef.current) {
        setProgress(100);
        completionTimerRef.current = setTimeout(() => {
          setProgress(0);
          wasProcessingRef.current = false;
        }, 500);
      } else {
        setProgress(0);
      }
    }

    return () => {
      if (progressTimerRef.current) {
        clearInterval(progressTimerRef.current);
        progressTimerRef.current = null;
      }
      if (completionTimerRef.current) {
        clearTimeout(completionTimerRef.current);
        completionTimerRef.current = null;
      }
    };
  }, [isProcessing, isRecognizing]);

  const resetProcessingState = () => {
    if (progressTimerRef.current) {
      clearInterval(progressTimerRef.current);
      progressTimerRef.current = null;
    }
    if (completionTimerRef.current) {
      clearTimeout(completionTimerRef.current);
      completionTimerRef.current = null;
    }

    setIsProcessing(false);
    wasProcessingRef.current = false;
    setProgress(0);
    setProgressMessage('');
    setInterimTranscript('');
    setFinalTranscriptDisplay('');
    finalTranscriptRef.current = '';
    interimTranscriptRef.current = '';

    if (fileInputRef.current) {
      fileInputRef.current.value = '';
    }
    if (cameraInputRef.current) {
      cameraInputRef.current.value = '';
    }
  };

  const handleCancelProcessing = () => {
    resetProcessingState();
    onCancelRecognition?.();
  };

  const readFileAsDataURL = (file: File): Promise<string> => {
    return new Promise((resolve, reject) => {
      const reader = new FileReader();
      reader.onload = () => resolve(reader.result as string);
      reader.onerror = () => reject(new Error('è¯»å–æ–‡ä»¶å¤±è´¥'));
      reader.readAsDataURL(file);
    });
  };

  const handleFileUpload = async (e: React.ChangeEvent<HTMLInputElement>) => {
    const file = e.target.files?.[0];
    if (!file) return;

    if (!file.type.startsWith('image/')) {
      alert('è¯·ä¸Šä¼ å›¾ç‰‡æ–‡ä»¶');
      return;
    }

    try {
      setProgressMessage('æ‰‹å†™ä½œæ–‡è¯†åˆ«ä¸­ï¼Œè¯·ç¨å€™...');
      const base64Data = await readFileAsDataURL(file);
      await onImageCapture(base64Data);
    } catch (error) {
      if (error instanceof DOMException && error.name === 'AbortError') {
        console.info('å›¾ç‰‡ä¸Šä¼ è¯†åˆ«å·²å–æ¶ˆ');
      } else {
        console.error('ä¸Šä¼ å›¾ç‰‡å¤±è´¥:', error);
        alert('ä¸Šä¼ å›¾ç‰‡å¤±è´¥');
      }
    } finally {
      if (fileInputRef.current) {
        fileInputRef.current.value = '';
      }
    }
  };

  const handleCameraCapture = async (e: React.ChangeEvent<HTMLInputElement>) => {
    const file = e.target.files?.[0];
    if (!file) return;

    try {
      setProgressMessage('æ‰‹å†™ä½œæ–‡è¯†åˆ«ä¸­ï¼Œè¯·ç¨å€™...');
      const base64Data = await readFileAsDataURL(file);
      await onImageCapture(base64Data);
    } catch (error) {
      if (error instanceof DOMException && error.name === 'AbortError') {
        console.info('æ‹ç…§è¯†åˆ«å·²å–æ¶ˆ');
      } else {
        console.error('æ‹ç…§å¤±è´¥:', error);
        alert('æ‹ç…§å¤±è´¥');
      }
    } finally {
      if (cameraInputRef.current) {
        cameraInputRef.current.value = '';
      }
    }
  };

  const startRecording = async () => {
    try {
      const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
      
      if (!SpeechRecognition) {
        alert('æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«ï¼Œè¯·ä½¿ç”¨ Chromeã€Edge æˆ– Safari æµè§ˆå™¨');
        return;
      }

      // å…ˆè¯·æ±‚éº¦å…‹é£æƒé™ï¼Œè¿™æ · SpeechRecognition å’Œ MediaRecorder éƒ½å¯ä»¥ä½¿ç”¨
      console.log('â†’ è¯·æ±‚éº¦å…‹é£æƒé™...');
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      mediaStreamRef.current = stream;
      console.log('âœ“ éº¦å…‹é£æƒé™å·²è·å–');

      // åˆå§‹åŒ–è½¬å½•æ–‡æœ¬
      finalTranscriptRef.current = '';
      interimTranscriptRef.current = '';
      setInterimTranscript('');
      setFinalTranscriptDisplay('');

      // åˆ›å»ºå¹¶é…ç½®è¯­éŸ³è¯†åˆ«
      const recognition = new SpeechRecognition();
      recognitionRef.current = recognition;
      
      recognition.lang = 'zh-CN';
      recognition.continuous = true;
      recognition.interimResults = true;
      recognition.maxAlternatives = 1;

      isRecognitionActiveRef.current = true;

      recognition.onstart = () => {
        console.log('âœ“ è¯­éŸ³è¯†åˆ«å·²å¯åŠ¨');
      };

      recognition.onresult = (event: any) => {
        console.log('âœ“ æ¥æ”¶åˆ°è¯­éŸ³è¯†åˆ«ç»“æœ, resultIndex:', event.resultIndex, 'results.length:', event.results.length);
        let interimText = '';
        let finalText = finalTranscriptRef.current;

        for (let i = event.resultIndex; i < event.results.length; i++) {
          const transcript = event.results[i][0].transcript;
          const isFinal = event.results[i].isFinal;
          console.log(`  ç»“æœ ${i}: "${transcript}" (${isFinal ? 'final' : 'interim'})`);
          if (isFinal) {
            finalText += transcript;
          } else {
            interimText += transcript;
          }
        }

        finalTranscriptRef.current = finalText;
        interimTranscriptRef.current = interimText;
        setFinalTranscriptDisplay(finalText);
        setInterimTranscript(interimText);
        console.log('  ç´¯è®¡ final:', finalText);
        console.log('  å½“å‰ interim:', interimText);
      };

      recognition.onerror = (event: any) => {
        console.error('âœ— è¯­éŸ³è¯†åˆ«é”™è¯¯:', event.error, event);
        if (event.error === 'not-allowed') {
          alert('è¯·å…è®¸éº¦å…‹é£æƒé™ä»¥ä½¿ç”¨è¯­éŸ³è¯†åˆ«åŠŸèƒ½');
          isRecognitionActiveRef.current = false;
        } else if (event.error === 'audio-capture') {
          console.error('âœ— æ— æ³•è®¿é—®éº¦å…‹é£ï¼Œå¯èƒ½è¢«å…¶ä»–ç¨‹åºå ç”¨');
          isRecognitionActiveRef.current = false;
        } else if (event.error !== 'no-speech' && event.error !== 'aborted') {
          console.warn(`âš  è¯­éŸ³è¯†åˆ«é‡åˆ°é—®é¢˜: ${event.error}`);
        }
      };

      recognition.onend = () => {
        console.log('â€¢ è¯­éŸ³è¯†åˆ«ç»“æŸ, isActive:', isRecognitionActiveRef.current);

        if (recognitionEndDeferredRef.current) {
          recognitionEndDeferredRef.current.resolve();
          recognitionEndDeferredRef.current = null;
        }

        if (isRecognitionActiveRef.current && recognitionRef.current === recognition) {
          console.log('â†’ å‡†å¤‡é‡å¯è¯­éŸ³è¯†åˆ«...');
          setTimeout(() => {
            if (recognitionRef.current === recognition && isRecognitionActiveRef.current) {
              try {
                recognition.start();
                console.log('â†» è¯­éŸ³è¯†åˆ«å·²é‡å¯');
              } catch (error) {
                console.error('âœ— é‡æ–°å¯åŠ¨è¯­éŸ³è¯†åˆ«å¤±è´¥:', error);
                isRecognitionActiveRef.current = false;
              }
            }
          }, 150);
        } else {
          if (recognitionRef.current === recognition) {
            recognitionRef.current = null;
          }
        }
      };

      // å¯åŠ¨è¯­éŸ³è¯†åˆ«
      console.log('â†’ å¯åŠ¨è¯­éŸ³è¯†åˆ«...');
      recognition.start();

      // TODO: æš‚æ—¶ç¦ç”¨å½•éŸ³åŠŸèƒ½ï¼Œåªæµ‹è¯•è¯­éŸ³è¯†åˆ«
      // å¯åŠ¨å½•éŸ³ï¼ˆä½¿ç”¨ç›¸åŒçš„éŸ³é¢‘æµï¼‰
      // const mediaRecorder = new MediaRecorder(stream);
      // mediaRecorderRef.current = mediaRecorder;
      // audioChunksRef.current = [];

      // mediaRecorder.ondataavailable = (event) => {
      //   if (event.data.size > 0) {
      //     audioChunksRef.current.push(event.data);
      //   }
      // };

      // mediaRecorder.onstop = null;
      // mediaRecorder.start();
      console.log('âœ“ å½•éŸ³å·²å¼€å§‹ï¼ˆä»…è¯­éŸ³è¯†åˆ«ï¼Œä¸ä¿å­˜éŸ³é¢‘ï¼‰');
      
      setIsRecording(true);
      setRecordingTime(0);

      recordingTimerRef.current = setInterval(() => {
        setRecordingTime(prev => prev + 1);
      }, 1000);
    } catch (error) {
      console.error('âœ— å¯åŠ¨å½•éŸ³å¤±è´¥:', error);
      isRecognitionActiveRef.current = false;
      if (recognitionRef.current) {
        try {
          recognitionRef.current.stop();
        } catch (e) {
          console.error('åœæ­¢è¯­éŸ³è¯†åˆ«å¤±è´¥:', e);
        }
        recognitionRef.current = null;
      }
      if (mediaStreamRef.current) {
        mediaStreamRef.current.getTracks().forEach(track => track.stop());
        mediaStreamRef.current = null;
      }
      const errorMessage = error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯';
      alert(`æ— æ³•å¯åŠ¨è¯­éŸ³å½•åˆ¶: ${errorMessage}\nè¯·æ£€æŸ¥éº¦å…‹é£æƒé™è®¾ç½®`);
    }
  };

  const stopRecording = async () => {
    if (isRecording) {
      setIsRecording(false);
      console.log('â†’ åœæ­¢å½•éŸ³...');
      
      if (recordingTimerRef.current) {
        clearInterval(recordingTimerRef.current);
        recordingTimerRef.current = null;
      }

      if (recognitionRef.current) {
        console.log('â†’ åœæ­¢è¯­éŸ³è¯†åˆ«...');
        console.log('  å½“å‰ finalTranscriptRef:', finalTranscriptRef.current);
        console.log('  å½“å‰ interimTranscriptRef:', interimTranscriptRef.current);
        
        isRecognitionActiveRef.current = false;
        const recognitionInstance = recognitionRef.current;
        const endDeferred = createDeferred();
        recognitionEndDeferredRef.current = endDeferred;

        try {
          recognitionInstance.stop();
        } catch (error) {
          console.error('åœæ­¢è¯­éŸ³è¯†åˆ«æ—¶å‘ç”Ÿé”™è¯¯:', error);
          recognitionEndDeferredRef.current = null;
        }

        if (recognitionEndDeferredRef.current) {
          await Promise.race([
            recognitionEndDeferredRef.current.promise,
            new Promise(resolve => setTimeout(resolve, 1000))
          ]);
        }

        recognitionEndDeferredRef.current = null;
        recognitionRef.current = null;
        console.log('âœ“ è¯­éŸ³è¯†åˆ«å·²åœæ­¢');
        console.log('  æœ€ç»ˆ finalTranscriptRef:', finalTranscriptRef.current);
        console.log('  æœ€ç»ˆ interimTranscriptRef:', interimTranscriptRef.current);
      }

      const combinedTranscript = (
        `${finalTranscriptRef.current} ${interimTranscriptRef.current}`
          .replace(/\s+/g, ' ')
          .trim()
      );

      setIsProcessing(true);
      setProgressMessage('æ­£åœ¨å¤„ç†è¯­éŸ³è¯†åˆ«ç»“æœ...');

      try {
        console.log('ğŸ¤ æœ€ç»ˆè¯†åˆ«ç»“æœ:', combinedTranscript);
        await onAudioCapture({
          audioData: '',
          transcript: combinedTranscript
        });
      } finally {
        setIsProcessing(false);
        setProgressMessage('');
        finalTranscriptRef.current = '';
        interimTranscriptRef.current = '';
        setInterimTranscript('');
        setFinalTranscriptDisplay('');
      }

      if (mediaStreamRef.current) {
        mediaStreamRef.current.getTracks().forEach(track => track.stop());
        mediaStreamRef.current = null;
      }
    }
  };

  const formatTime = (seconds: number) => {
    const mins = Math.floor(seconds / 60);
    const secs = seconds % 60;
    return `${mins}:${secs.toString().padStart(2, '0')}`;
  };

  const progressPercentage = Math.min(Math.round(progress), 100);
  const showProgress = isRecognizing || isProcessing || progress > 0;

  if (showProgress) {
    return (
      <div className="flex flex-col items-center justify-center gap-4 p-10 border-2 border-morandi-gray-300 rounded-xl bg-white text-center">
        <Loader2 className="w-12 h-12 text-morandi-blue-500 animate-spin" />
        <div>
          <p className="text-morandi-gray-700 font-medium">
            {progressMessage || 'æ­£åœ¨è¯†åˆ«æ‰‹å†™ä½œæ–‡ï¼Œè¯·ç¨å€™...'}
          </p>
          <p className="text-xs text-morandi-gray-500 mt-1">å¦‚æœè¯†åˆ«æ—¶é—´è¾ƒé•¿ï¼Œè¯·ç¨å€™ç‰‡åˆ»</p>
        </div>
        <div className="w-full max-w-xs h-2 bg-morandi-gray-200 rounded-full overflow-hidden">
          <div
            className="h-full bg-morandi-blue-500 transition-all duration-300"
            style={{ width: `${progressPercentage}%` }}
          />
        </div>
        <p className="text-xs text-morandi-gray-500 mb-2">{progressPercentage}%</p>
        {onCancelRecognition && isRecognizing && (
          <button
            onClick={handleCancelProcessing}
            className="px-6 py-2 bg-morandi-red-500 hover:bg-morandi-red-600 text-white font-medium rounded-lg transition-colors shadow-md hover:shadow-lg"
          >
            å–æ¶ˆè¯†åˆ«
          </button>
        )}
      </div>
    );
  }

  if (currentImage) {
    return (
      <div className="relative border-2 border-morandi-gray-300 rounded-xl p-4 bg-white">
        <div className="flex items-center justify-between mb-4">
          <h3 className="text-sm font-medium text-morandi-gray-700">æ‰‹å†™ä½œæ–‡å›¾ç‰‡</h3>
          <button
            onClick={onClear}
            disabled={disabled}
            className="p-2 text-morandi-gray-600 hover:text-morandi-red-600 hover:bg-morandi-red-50 rounded-lg transition-colors disabled:opacity-50"
            title="æ¸…é™¤å›¾ç‰‡å¹¶æ¢å¤ç¨¿çº¸"
          >
            <X className="w-5 h-5" />
          </button>
        </div>
        <img
          src={currentImage}
          alt="æ‰‹å†™ä½œæ–‡"
          className="w-full h-auto max-h-[600px] object-contain rounded-lg shadow-md"
        />
      </div>
    );
  }

  if (currentAudio) {
    return (
      <div className="relative border-2 border-morandi-gray-300 rounded-xl p-4 bg-white">
        <div className="flex items-center justify-between mb-4">
          <h3 className="text-sm font-medium text-morandi-gray-700">è¯­éŸ³ä½œæ–‡</h3>
          <button
            onClick={onClear}
            disabled={disabled}
            className="p-2 text-morandi-gray-600 hover:text-morandi-red-600 hover:bg-morandi-red-50 rounded-lg transition-colors disabled:opacity-50"
            title="æ¸…é™¤éŸ³é¢‘å¹¶æ¢å¤ç¨¿çº¸"
          >
            <X className="w-5 h-5" />
          </button>
        </div>
        <audio
          src={currentAudio}
          controls
          className="w-full"
        />
      </div>
    );
  }

  return (
    <div className="space-y-4">
      <div className="grid grid-cols-1 sm:grid-cols-3 gap-4">
        <button
          onClick={() => fileInputRef.current?.click()}
          disabled={disabled || isRecording || isProcessing || isRecognizing}
          className="flex flex-col items-center justify-center gap-2 p-6 border-2 border-dashed border-morandi-gray-300 rounded-xl hover:border-morandi-blue-500 hover:bg-morandi-blue-50 transition-all disabled:opacity-50 disabled:cursor-not-allowed"
        >
          <Upload className="w-8 h-8 text-morandi-blue-600" />
          <span className="text-sm font-medium text-morandi-gray-700">ä¸Šä¼ å›¾ç‰‡</span>
          <span className="text-xs text-morandi-gray-500">æ”¯æŒ JPGã€PNG ç­‰æ ¼å¼</span>
        </button>

        <button
          onClick={() => cameraInputRef.current?.click()}
          disabled={disabled || isRecording || isProcessing || isRecognizing}
          className="flex flex-col items-center justify-center gap-2 p-6 border-2 border-dashed border-morandi-gray-300 rounded-xl hover:border-morandi-green-500 hover:bg-morandi-green-50 transition-all disabled:opacity-50 disabled:cursor-not-allowed"
        >
          <Camera className="w-8 h-8 text-morandi-green-600" />
          <span className="text-sm font-medium text-morandi-gray-700">æ‹æ‘„ç…§ç‰‡</span>
          <span className="text-xs text-morandi-gray-500">ä½¿ç”¨ç›¸æœºæ‹æ‘„æ‰‹å†™ä½œæ–‡</span>
        </button>

        {!isRecording ? (
          <button
            onClick={startRecording}
            disabled={disabled || isProcessing || isRecognizing}
            className="flex flex-col items-center justify-center gap-2 p-6 border-2 border-dashed border-morandi-gray-300 rounded-xl hover:border-morandi-pink-500 hover:bg-morandi-pink-50 transition-all disabled:opacity-50 disabled:cursor-not-allowed"
          >
            <Mic className="w-8 h-8 text-morandi-pink-600" />
            <span className="text-sm font-medium text-morandi-gray-700">è¯­éŸ³å½•åˆ¶</span>
            <span className="text-xs text-morandi-gray-500">å½•åˆ¶ä½ çš„ä½œæ–‡æœ—è¯»</span>
          </button>
        ) : (
          <button
            onClick={stopRecording}
            className="flex flex-col items-center justify-center gap-2 p-6 border-2 border-morandi-pink-500 bg-morandi-pink-50 rounded-xl animate-pulse"
          >
            <div className="w-8 h-8 bg-morandi-pink-600 rounded-full flex items-center justify-center">
              <div className="w-4 h-4 bg-white rounded-sm"></div>
            </div>
            <span className="text-sm font-medium text-morandi-pink-700">åœæ­¢å½•éŸ³</span>
            <span className="text-xs text-morandi-pink-600 font-mono">{formatTime(recordingTime)}</span>
          </button>
        )}
      </div>

      {isRecording && (finalTranscriptDisplay || interimTranscript) && (
        <div className="mt-4 p-4 bg-morandi-pink-50 border border-morandi-pink-200 rounded-xl">
          <h4 className="text-sm font-medium text-morandi-pink-800 mb-2 flex items-center gap-2">
            <Mic className="w-4 h-4" />
            å®æ—¶è¯†åˆ«
          </h4>
          <div className="text-sm text-morandi-gray-700 space-y-1">
            {finalTranscriptDisplay && (
              <p className="font-medium">{finalTranscriptDisplay}</p>
            )}
            {interimTranscript && (
              <p className="text-morandi-gray-500 italic">{interimTranscript}</p>
            )}
          </div>
        </div>
      )}

      <input
        ref={fileInputRef}
        type="file"
        accept="image/*"
        onChange={handleFileUpload}
        className="hidden"
      />

      <input
        ref={cameraInputRef}
        type="file"
        accept="image/*"
        capture="environment"
        onChange={handleCameraCapture}
        className="hidden"
      />
    </div>
  );
}
